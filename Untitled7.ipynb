{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevivJaknap/Story/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmNW7SOCR_AR"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FJ0bfuDqSFDf"
      },
      "outputs": [],
      "source": [
        "from gym import spaces\n",
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class GridWorldEnv(gym.Env):\n",
        "\n",
        "  def __init__(self,size=6):\n",
        "\n",
        "    self.size=size\n",
        "\n",
        "    self.target_state=[3,3]\n",
        "    self.agent_state=[0,0]\n",
        "    self.board_state = np.zeros([6,6], dtype=np.int32)\n",
        "    self.board_state[3][3] = 2\n",
        "    self.board_state[0][0] = -2\n",
        "    self.action_to_direction = {\n",
        "        \n",
        "        0: np.array([1, 0]),\n",
        "        1: np.array([0, 1]),\n",
        "        2: np.array([-1, 0]),\n",
        "        3: np.array([0, -1]),\n",
        "\n",
        "        }\n",
        "\n",
        "    self.action_space=spaces.Discrete(4)\n",
        "    self.observation_space=spaces.Box(low=-2,high=2,shape=(6*6,),dtype=np.int32)\n",
        "\n",
        "    self.steps=0\n",
        "    # self.step_limit= 50\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.agent_state=[0,0]\n",
        "    self.board_state = np.zeros([6, 6], dtype=np.int32)\n",
        "    self.board_state[0][0] = -2\n",
        "    self.board_state[3][3] = 2\n",
        "    self.steps=0\n",
        "    return self.board_state.copy().flatten()\n",
        "\n",
        "  def step(self,action):\n",
        "\n",
        "    self.steps+=1\n",
        "    done=False\n",
        "    direction= self.action_to_direction[action]\n",
        "    x, y = self.agent_state\n",
        "    self.board_state[x][y] = 0\n",
        "    self.agent_state= np.clip(self.agent_state + direction,0,self.size-1)\n",
        "    x, y = self.agent_state\n",
        "    self.board_state[x][y] = -2\n",
        "    reward=0\n",
        "    \n",
        "    err= np.linalg.norm(self.target_state-self.agent_state)\n",
        "    reward+= -err*10\n",
        "    \n",
        "    if (self.agent_state==self.target_state).all():\n",
        "      reward+=50\n",
        "      done=True\n",
        "\n",
        "    # if self.steps>self.step_limit:\n",
        "    #   reward-=5\n",
        "    #   done=True  \n",
        "\n",
        "    return self.board_state.flatten(), reward, done, {}\n",
        "\n",
        "\n",
        "  def render(self):\n",
        "    print(self.board_state)\n",
        "\n",
        "  def close(self):\n",
        "    pass         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mJ6iOuvCSI-1"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "env = GridWorldEnv()\n",
        "# It will check your custom environment and output additional warnings if needed\n",
        "check_env(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gmfN6YQASLaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a875197c-17e0-4301-bcda-417a995a0a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 61.5      |\n",
            "|    ep_rew_mean        | -1.53e+03 |\n",
            "| time/                 |           |\n",
            "|    fps                | 420       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 1         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.37     |\n",
            "|    explained_variance | 0.00287   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -16.2     |\n",
            "|    value_loss         | 4.28e+03  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 52.1      |\n",
            "|    ep_rew_mean        | -1.29e+03 |\n",
            "| time/                 |           |\n",
            "|    fps                | 443       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.36     |\n",
            "|    explained_variance | 0.000478  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -166      |\n",
            "|    value_loss         | 1.53e+04  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.3      |\n",
            "|    ep_rew_mean        | -1.23e+03 |\n",
            "| time/                 |           |\n",
            "|    fps                | 452       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.36     |\n",
            "|    explained_variance | -0.000519 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -49.4     |\n",
            "|    value_loss         | 1.81e+03  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 42.3      |\n",
            "|    ep_rew_mean        | -1.05e+03 |\n",
            "| time/                 |           |\n",
            "|    fps                | 453       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.35     |\n",
            "|    explained_variance | 0.000254  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -132      |\n",
            "|    value_loss         | 1.05e+04  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 36.5      |\n",
            "|    ep_rew_mean        | -890      |\n",
            "| time/                 |           |\n",
            "|    fps                | 458       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.31     |\n",
            "|    explained_variance | -7.53e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -95.2     |\n",
            "|    value_loss         | 5.27e+03  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.5     |\n",
            "|    ep_rew_mean        | -761     |\n",
            "| time/                 |          |\n",
            "|    fps                | 462      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.04    |\n",
            "|    explained_variance | 0.0352   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 35.3     |\n",
            "|    value_loss         | 3.18e+03 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.4     |\n",
            "|    ep_rew_mean        | -440     |\n",
            "| time/                 |          |\n",
            "|    fps                | 464      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.938   |\n",
            "|    explained_variance | 0.237    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 15.6     |\n",
            "|    value_loss         | 2.88e+03 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 13.7     |\n",
            "|    ep_rew_mean        | -275     |\n",
            "| time/                 |          |\n",
            "|    fps                | 466      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.858   |\n",
            "|    explained_variance | 0.346    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -0.369   |\n",
            "|    value_loss         | 852      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.9      |\n",
            "|    ep_rew_mean        | -167     |\n",
            "| time/                 |          |\n",
            "|    fps                | 467      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.721   |\n",
            "|    explained_variance | 0.691    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 1.71     |\n",
            "|    value_loss         | 407      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 7.26     |\n",
            "|    ep_rew_mean        | -98.3    |\n",
            "| time/                 |          |\n",
            "|    fps                | 465      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.63    |\n",
            "|    explained_variance | 0.9      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -1.02    |\n",
            "|    value_loss         | 199      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 7.15     |\n",
            "|    ep_rew_mean        | -94      |\n",
            "| time/                 |          |\n",
            "|    fps                | 465      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.877   |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -56.6    |\n",
            "|    value_loss         | 8.25e+03 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 7.15      |\n",
            "|    ep_rew_mean        | -94       |\n",
            "| time/                 |           |\n",
            "|    fps                | 464       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.14     |\n",
            "|    explained_variance | -0.000359 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -93.8     |\n",
            "|    value_loss         | 6.66e+03  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.4     |\n",
            "|    ep_rew_mean        | -305     |\n",
            "| time/                 |          |\n",
            "|    fps                | 465      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.498   |\n",
            "|    explained_variance | 0.923    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 1.26     |\n",
            "|    value_loss         | 149      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.96     |\n",
            "|    ep_rew_mean        | -87.2    |\n",
            "| time/                 |          |\n",
            "|    fps                | 467      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.358   |\n",
            "|    explained_variance | 0.992    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -68.2    |\n",
            "|    value_loss         | 4.8e+03  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8.33     |\n",
            "|    ep_rew_mean        | -124     |\n",
            "| time/                 |          |\n",
            "|    fps                | 465      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.479   |\n",
            "|    explained_variance | 0.998    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.51    |\n",
            "|    value_loss         | 2.93     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 7.06     |\n",
            "|    ep_rew_mean        | -92.3    |\n",
            "| time/                 |          |\n",
            "|    fps                | 466      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.336   |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0.0882  |\n",
            "|    value_loss         | 0.283    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.05     |\n",
            "|    ep_rew_mean        | -63.1    |\n",
            "| time/                 |          |\n",
            "|    fps                | 466      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.413   |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.0597  |\n",
            "|    value_loss         | 0.104    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.09     |\n",
            "|    ep_rew_mean        | -62.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 466      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.22    |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.0854   |\n",
            "|    value_loss         | 0.184    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.03     |\n",
            "|    ep_rew_mean        | -61.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 465      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.258   |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.00395  |\n",
            "|    value_loss         | 0.303    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.01     |\n",
            "|    ep_rew_mean        | -61.3    |\n",
            "| time/                 |          |\n",
            "|    fps                | 464      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.198   |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.0219   |\n",
            "|    value_loss         | 0.15     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.04     |\n",
            "|    ep_rew_mean        | -61.9    |\n",
            "| time/                 |          |\n",
            "|    fps                | 464      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.11    |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -0.0133  |\n",
            "|    value_loss         | 0.339    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.04     |\n",
            "|    ep_rew_mean        | -61.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 458      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0391  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.00123 |\n",
            "|    value_loss         | 0.126    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -61      |\n",
            "| time/                 |          |\n",
            "|    fps                | 451      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0293  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.00123  |\n",
            "|    value_loss         | 0.154    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -61      |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0265  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.000182 |\n",
            "|    value_loss         | 0.075    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0243  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.00112  |\n",
            "|    value_loss         | 0.12     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.04     |\n",
            "|    ep_rew_mean        | -61.3    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.13    |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00736  |\n",
            "|    value_loss         | 0.26     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 453      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0189  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.000995 |\n",
            "|    value_loss         | 0.2      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 453      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0175  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.000834 |\n",
            "|    value_loss         | 0.264    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.02     |\n",
            "|    ep_rew_mean        | -61.1    |\n",
            "| time/                 |          |\n",
            "|    fps                | 453      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.238   |\n",
            "|    explained_variance | -1.42    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | -33.5    |\n",
            "|    value_loss         | 752      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.02     |\n",
            "|    ep_rew_mean        | -61.1    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0164  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 0.000195 |\n",
            "|    value_loss         | 0.0653   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.02     |\n",
            "|    ep_rew_mean        | -61.1    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0117  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 0.000174 |\n",
            "|    value_loss         | 0.0646   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 451      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00948 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 0.000346 |\n",
            "|    value_loss         | 0.0781   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 451      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0201  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.000578 |\n",
            "|    value_loss         | 0.231    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 6         |\n",
            "|    ep_rew_mean        | -60.8     |\n",
            "| time/                 |           |\n",
            "|    fps                | 452       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.015    |\n",
            "|    explained_variance | 1         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -0.000254 |\n",
            "|    value_loss         | 0.0992    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.02     |\n",
            "|    ep_rew_mean        | -61.1    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0112  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.00022  |\n",
            "|    value_loss         | 0.106    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6.02     |\n",
            "|    ep_rew_mean        | -61.5    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00863 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.000159 |\n",
            "|    value_loss         | 0.104    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00634 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.000173 |\n",
            "|    value_loss         | 0.0858   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 453      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00921 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 7.24e-05 |\n",
            "|    value_loss         | 0.0872   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00845 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 0.000153 |\n",
            "|    value_loss         | 0.103    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00636 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 0.000133 |\n",
            "|    value_loss         | 0.0418   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 20500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00852 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | 6.87e-05 |\n",
            "|    value_loss         | 0.0702   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 6         |\n",
            "|    ep_rew_mean        | -60.9     |\n",
            "| time/                 |           |\n",
            "|    fps                | 452       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00965  |\n",
            "|    explained_variance | 1         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | -0.000318 |\n",
            "|    value_loss         | 0.132     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 6         |\n",
            "|    ep_rew_mean        | -60.8     |\n",
            "| time/                 |           |\n",
            "|    fps                | 452       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 21500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00624  |\n",
            "|    explained_variance | 1         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | -0.000112 |\n",
            "|    value_loss         | 0.025     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 48       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0192  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | 0.000567 |\n",
            "|    value_loss         | 0.0629   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 49       |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0139  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | 0.000497 |\n",
            "|    value_loss         | 0.0623   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 6         |\n",
            "|    ep_rew_mean        | -60.8     |\n",
            "| time/                 |           |\n",
            "|    fps                | 452       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 50        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00626  |\n",
            "|    explained_variance | 1         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | -0.000132 |\n",
            "|    value_loss         | 0.0379    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 4700     |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 23500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.0103  |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4699     |\n",
            "|    policy_loss        | 8.06e-05 |\n",
            "|    value_loss         | 0.0763   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 52       |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00369 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | -4e-05   |\n",
            "|    value_loss         | 0.0561   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 6.02      |\n",
            "|    ep_rew_mean        | -61.5     |\n",
            "| time/                 |           |\n",
            "|    fps                | 453       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.00475  |\n",
            "|    explained_variance | 1         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | -6.65e-05 |\n",
            "|    value_loss         | 0.0524    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 6        |\n",
            "|    ep_rew_mean        | -60.8    |\n",
            "| time/                 |          |\n",
            "|    fps                | 452      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.00456 |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | 9.12e-05 |\n",
            "|    value_loss         | 0.0389   |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7f7c3015c890>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from stable_baselines3 import DQN, A2C\n",
        "# model2 = DQN(\"MlpPolicy\", env, verbose=1)\n",
        "# model2.learn(total_timesteps=10000, log_interval=4)\n",
        "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=25000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "env = GridWorldEnv()\n",
        "\n",
        "obs = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "# Hardcoded best agent: always go left!\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  act = random.randint(0, 3)\n",
        "  obs, reward, done, info = env.step(act)\n",
        "  print('action= ', act, 'obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "metadata": {
        "id": "RYiBeFO9YcQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained agent\n",
        "obs = env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  print(\"Action: \", int(action))\n",
        "  obs, reward, done, info = env.step(int(action))\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render()\n",
        "  if done:\n",
        "    # Note that the VecEnv resets automatically\n",
        "    # when a done signal is encountered\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vpw4K-FbEYY",
        "outputId": "fa0782e9-1353-43f0-c718-86d656aefc24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            "Action:  0\n",
            "obs= [ 0  0  0  0  0  0 -2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0] reward= -36.05551275463989 done= False\n",
            "[[ 0  0  0  0  0  0]\n",
            " [-2  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]]\n",
            "Step 2\n",
            "Action:  1\n",
            "obs= [ 0  0  0  0  0  0  0 -2  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0] reward= -28.284271247461902 done= False\n",
            "[[ 0  0  0  0  0  0]\n",
            " [ 0 -2  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]]\n",
            "Step 3\n",
            "Action:  0\n",
            "obs= [ 0  0  0  0  0  0  0  0  0  0  0  0  0 -2  0  0  0  0  0  0  0  2  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0] reward= -22.360679774997898 done= False\n",
            "[[ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0 -2  0  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]]\n",
            "Step 4\n",
            "Action:  1\n",
            "obs= [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 -2  0  0  0  0  0  0  2  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0] reward= -14.142135623730951 done= False\n",
            "[[ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0 -2  0  0  0]\n",
            " [ 0  0  0  2  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]]\n",
            "Step 5\n",
            "Action:  0\n",
            "obs= [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -2  2  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0] reward= -10.0 done= False\n",
            "[[ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0 -2  2  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]]\n",
            "Step 6\n",
            "Action:  1\n",
            "obs= [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -2  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0] reward= 50.0 done= True\n",
            "[[ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0 -2  0  0]\n",
            " [ 0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0]]\n",
            "Goal reached! reward= 50.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy1inyQrLfC/b6tjbnIun6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}